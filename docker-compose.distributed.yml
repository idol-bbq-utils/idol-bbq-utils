# Distributed deployment for idol-bbq-utils
# This configuration splits the monolithic tweet-forwarder into separate services:
# - crawler-service: Handles web scraping with browser pool + integrated storage (翻译 + 存储)
# - sender-service: Handles message forwarding to platforms
#
# Usage:
#   docker-compose -f docker-compose.distributed.yml up -d
#
# Scaling crawlers:
#   docker-compose -f docker-compose.distributed.yml up -d --scale crawler=3

services:
  redis:
    image: redis:7-alpine
    container_name: idol-bbq-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

  postgres:
    image: postgres:16-alpine
    container_name: idol-bbq-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: idol_bbq
      POSTGRES_PASSWORD: idol_bbq_password
      POSTGRES_DB: idol_bbq
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U idol_bbq"]
      interval: 10s
      timeout: 5s
      retries: 5

  scheduler:
    build:
      context: .
      dockerfile: app/scheduler-service/Dockerfile
    container_name: idol-bbq-scheduler
    restart: unless-stopped
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=info
      - TZ=Asia/Shanghai
      - DATABASE_URL=file:/app/data.db
    volumes:
      - ./config.yaml:/app/config.yaml:ro
      - ./assets:/app/assets:ro
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Bull Board - Queue monitoring dashboard
  bull-board:
    image: deadly0/bull-board:latest
    container_name: idol-bbq-bull-board
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_USE_TLS: "false"
      BULL_PREFIX: "bull"
    depends_on:
      redis:
        condition: service_healthy

  # Crawler Service - Web scraping workers with browser pool + integrated storage
  crawler:
    build:
      context: .
      dockerfile: app/crawler-service/Dockerfile
    restart: unless-stopped
    environment:
      - TZ=Asia/Tokyo
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - WORKER_CONCURRENCY=2
      - BROWSER_POOL_SIZE=2
      - STORAGE_QUEUE_CONCURRENCY=3
      - NO_SANDBOX=true
      - LOG_LEVEL=debug
      - DATABASE_URL=file:/app/data.db
    volumes:
      - ./assets/refactor.db:/app/data.db
      - ./assets/cookies:/app/assets/cookies  # Cookie files for authenticated crawling
      - ./assets/fonts:/app/assets/fonts      # Font files for rendering
      - /tmp/tweet-forwarder/logs:/tmp/tweet-forwarder/logs    # Log directory
      - /tmp/tweet-forwarder/media:/tmp/tweet-forwarder/media  # Media cache
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G



volumes:
  redis_data:
  postgres_data:
